## This part relates to the extra exercise involving the scrappiers/crawlers to get clients store location

The scripts were made with javascript + node (and a bunch of npm packages of course :) )

To execute, you must have node and npm installed.

them just download moduled: `npm install`
and run the script you want, like: `node crawlerAmericanas.js`

1- Lojas Americas (cerca de 1500 endereços disponíveis em:
http://www.americanas.com.br/lasa )
R: file crawlerAmericanas.js

2- Postos Petrobras (cerca de 8000 endereços disponíveis em:
http://www.br.com.br/pc/rede-de-postos-petrobras )
R: file crawlerBR.js
I could not finish this one. I ended up using a headerless browser because every change on the selectors triggered a page reload with new data.
But after doing some submits to get the data for each city, it popped a capatch test :(
I also tried mimmic the POST with the form to get the data, but no success as well. There is probably a solution for this but I could not figure out on time.

3- Postos Shell (cerca de 6000 endereços disponíveis em:
https://www.shell.com.br/motoristas/localizador-de-postos.html.html )
I haven't really tried this one. But noticed most of the data is loaded with javascript. A headless browser approach might lead into something promising here as well.